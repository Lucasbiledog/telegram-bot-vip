#!/usr/bin/env python3
"""
Importa arquivos indexados do JSON para o banco de dados.
Execute este script NO SERVIDOR (Render) ou localmente ap√≥s gerar o JSON.
"""

import json
import sys
from datetime import datetime, timezone
from pathlib import Path

# Adicionar ao path
sys.path.insert(0, str(Path(__file__).parent))

from main import SessionLocal, SourceFile

def importar_arquivos(json_file='arquivos_indexados.json'):
    """Importa arquivos do JSON para o banco de dados"""

    print("\n" + "="*70)
    print("üì• IMPORTANDO ARQUIVOS PARA O BANCO")
    print("="*70)

    # Ler JSON
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            arquivos = json.load(f)
    except FileNotFoundError:
        print(f"\n‚ùå Arquivo {json_file} n√£o encontrado!")
        print("\nüí° Execute primeiro: python indexar_historico_local.py\n")
        return
    except json.JSONDecodeError:
        print(f"\n‚ùå Erro ao ler JSON. Arquivo corrompido?\n")
        return

    print(f"\nüìÅ {len(arquivos)} arquivos no JSON")
    print("‚è≥ Importando para o banco...\n")

    stats = {
        'importados': 0,
        'duplicados': 0,
        'erros': 0
    }

    with SessionLocal() as session:
        for i, arq in enumerate(arquivos, 1):
            # Progress a cada 100
            if i % 100 == 0:
                print(f"   üìä {i}/{len(arquivos)} processados | "
                      f"‚úÖ {stats['importados']} importados | "
                      f"‚è≠Ô∏è {stats['duplicados']} duplicados")

            try:
                # Verificar se j√° existe
                existing = session.query(SourceFile).filter(
                    SourceFile.file_unique_id == arq['file_unique_id']
                ).first()

                if existing:
                    stats['duplicados'] += 1
                    continue

                # Criar novo
                source_file = SourceFile(
                    file_id=arq['file_id'],
                    file_unique_id=arq['file_unique_id'],
                    file_type=arq['file_type'],
                    message_id=arq['message_id'],
                    source_chat_id=arq['source_chat_id'],
                    caption=arq.get('caption'),
                    file_name=arq.get('file_name'),
                    file_size=arq.get('file_size'),
                    indexed_at=datetime.now(timezone.utc),
                    active=True
                )
                session.add(source_file)
                session.commit()

                stats['importados'] += 1

            except Exception as e:
                session.rollback()
                stats['erros'] += 1
                print(f"   ‚ùå Erro no arquivo {i}: {e}")

        # Relat√≥rio final
        print("\n" + "="*70)
        print("‚úÖ IMPORTA√á√ÉO CONCLU√çDA!")
        print("="*70)
        print(f"\nüìä ESTAT√çSTICAS:")
        print(f"   ‚úÖ Importados: {stats['importados']}")
        print(f"   ‚è≠Ô∏è  Duplicados: {stats['duplicados']}")
        print(f"   ‚ùå Erros: {stats['erros']}")

        # Total no banco
        total_banco = session.query(SourceFile).filter(
            SourceFile.active == True
        ).count()

        print(f"\nüíæ Total no banco agora: {total_banco} arquivos")
        print("\n‚úÖ Pronto! Use /stats_auto no bot para ver as estat√≠sticas.\n")


if __name__ == "__main__":
    try:
        importar_arquivos()
    except KeyboardInterrupt:
        print("\n\n‚ùå Cancelado pelo usu√°rio.\n")
    except Exception as e:
        print(f"\n‚ùå Erro: {e}\n")
        import traceback
        traceback.print_exc()
